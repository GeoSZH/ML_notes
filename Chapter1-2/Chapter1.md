本篇笔记主要是用来查漏补缺，基础的知识可能一些并没有详细解释，主要是用于记录一些较为容易遗忘的知识点。

### Chapter1 绪论

#### 1.1 假设空间
从数据中学得模型所对应的关于数据的某种潜在规律，称之为**假设**。

这种潜在规律自身，则称之为**真相**或**真实**。学习过程就是为了找出或逼近真相。而我们可以把学习过程看作是一个在所有假设组成的空间中进行搜索的过程，这个空间即是**假设空间**，搜索目标则是找到与训练集匹配的假设，即能在训练集中**判断正确**的假设。

#### 1.2 归纳偏好
![image](https://user-images.githubusercontent.com/88269254/169642252-e453dc14-cc28-4b64-aa80-38873b607c80.png)
![image](https://user-images.githubusercontent.com/88269254/169642314-5944368f-718d-4b99-a13b-49bb8a3d057c.png)

我们根据表1.1提供的训练集可以得出表格下方能够使训练集一致的三个假设（其中的'* '代表**通配符**）,那么基于现有的样本无法断定上述的三个假设中哪一个“**更好**”，但是对于一个具体的学习算法而言，它必须产生**一个**模型。这时，学习算法本身的“偏好”就会起到关键作用。例如，若我们的算法喜欢"**尽可能特殊**"的模型，则它会选择"(色泽= * )^(根蒂=蜷缩)^(敲声=浊响) = 好瓜" ;但若我们的算法喜欢"**尽可能一般**"的模型，并且由于某种原因它更"相信"根蒂，则它会选择"(色泽= * )^(根蒂=蜷缩)^(敲声= * ) = 好瓜" 。机器学习算法在学习过程中对某种类型假设的偏好，称为"**归纳偏好**" (inductive bias) ,或简称为"**偏好**"。一个更直观的图如下，其中A，B可以认为是不同学习算法的可能偏好：

![image](https://user-images.githubusercontent.com/88269254/169643108-32f7c961-ea5c-4d29-8109-7a59cb94fd7d.png)

任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上"等效"的假设所迷惑，而**无法产生确定的学习结果**。那么归纳偏好在我们使用算法过程中有什么影响呢？事实上，归纳偏好对应了学习算法本身所做出的关于"什么样的模型更好"的假设.在具体的现实问题中，这个假设是否成立，即**算法的归纳偏好是否与问题本身匹配**，大多数时候直接决定了算法能否取得好的性能。

对于一个学习算法A，若它在**某些问题**上比学习算法B好，则必然存在**另一些问题**，在那里B比A好。有趣的是，这个结论对任何算法均成立。也就是说哪怕把“**随机胡猜**”和最近大火的"**LightGBM**"。接下来是一些证明过程，摘自南瓜书和西瓜书（图片格式，未用LaTeX）。

![image](https://user-images.githubusercontent.com/88269254/169643675-547b5cbe-d089-4ff6-8692-eb74beec35a9.png)

![image](https://user-images.githubusercontent.com/88269254/169643547-ff5a2ab1-286b-40a3-b344-09fe326a47c6.png)

![image](https://user-images.githubusercontent.com/88269254/169643733-e28474a5-1b73-4378-b757-c8ece2d67655.png)


### Chapter2 模型评估与选择
#### 2.1 经验误差与过拟合
这里不详细介绍错误率，精度，误差等等概念。想主要总结一下过拟合和欠拟合出现的**原因以及解决方法**：

首先我们先看一张西瓜书里对过拟合和欠拟合介绍的一张图

![image](https://user-images.githubusercontent.com/88269254/169643980-c15f4a7c-30e1-477b-90f8-36ff4959f61c.png)

有很多中因素可能导致过拟合，其中比较经常出现的就是：

（1）训练数据较少

（2）模型复杂度较高

究其根本，就是由于**学习能力太过强大**，以至于把**不太一般的特征**都学到了。解决方案也可根据上面的原因而对症下药，比如说，**增加训练数据，降低模型复杂度，添加或者调大正则化系数，或是采用集成方法**来缓解过拟合带来的影响。

也有很多因素可以导致欠拟合，不过欠拟合相对于过拟合来说比较容易克服：

（1）特征不足

（2）特征与标签的关联性不强

这个根本原因跟过拟合相反，即**学习能力不足**，而我们要做的对症下药的操作就是，**添加新特征，使模型更复杂一些（对应决策树则是扩展分支，神经网络增加层数或者增加训练轮数），或者减小正则化系数**

#### 2.2 评估方法
其中包括留出法，交叉验证法，自助法等，这里只做简单介绍：

##### 2.3.1 留出法

将数据集D划分未两个互斥的集合，一个作为训练集S，一个作为测试集T，满足D=S∪T且S∩T=Ø，常见的划分为：大约2/3-4/5的样本用作训练，剩下的用作测试。需要注意的是：训练集和测试集的划分要尽可能保持数据分布的一致性，以便面由于分布的差异引入额外的偏差，常见的作法是采用**分层抽样**。同时，由于划分的随机性，单词的留出法结果往往不够稳定，一般要采用若干次随即划分，重复实验取平均值的做法。

##### 2.3.1 交叉验证法


##### 2.3.3 自助法
