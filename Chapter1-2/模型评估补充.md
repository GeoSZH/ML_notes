这里介绍百面机器学习书中与模型评估部分相关的思考题
### 模型评估
#### 评估指标的局限性
下面给出三个实例：

**实例1**：Hulu的奢侈品广告主们希望把广告定向投放给奢侈品用户。Hulu通过第三方的数据管理平台（Data Management Platform，DMP）拿到了一部分奢侈品用户的数据，并以此为训练集和测试集，训练和测试奢侈品用户的分类模型。该模型的分类准确率超过了95%，但在实际广告投放过程中，该模型还是把大部分广告投给了非奢侈品用户，这可能是什么原因造成的？

**实例2**：Hulu提供视频的模糊搜索功能，搜索排序模型返回的Top 5的精确率非常高，但在实际使用过程中，用户还是经常找不到想要的视频，特别是一些比较冷门的剧集，这可能是哪个环节出了问题呢？

**实例3**：Hulu作为一家流媒体公司，拥有众多的美剧资源，预测每部美剧的流量趋势对于广告投放、用户增长都非常重要。我们希望构建一个回归模型来预测某部美剧的流量趋势，但无论采用哪种回归模型，得到的RMSE指标都非常高。然而事实是，模型在95%的时间区间内的预测误差都小于1%，取得了相当不错的预测结果。那么，造成RMSE指标居高不下的最可能的原因是什么？

这里实例1的意义是当负样本的比例非常高时，准确率指标就不管用了，虽然按照题目中的介绍，仍有很多其他原因，数据集划分，A/B测试差异，模型过拟合或者欠拟合等，但评估指标往往是最显而易见的。

实例2的问题则可以参考下图：

![image](https://user-images.githubusercontent.com/88269254/169730369-c85a06f3-ab87-407c-b61e-652ef0f340a3.png)

由图可见，当召回率接近于0时，模型A的精确率为0.9，模型B的精确率是1，这说明模型B得分前几位的样本全部是真正的正样本，而模型A即使得分最高的几个样本也存在预测错误的情况。并且，随着召回率的增加，精确率整体呈下降趋势。但是，当召回率为1时，模型A的精确率反而超过了模型B。这充分说明，只用某个点对应的精确率和召回率是不能全面地衡量模型的性能，只有通过P-R曲线的整体表现，才能够对模型进行更为全面的评估。

实例3则是有可能存在个别离群点偏离程度非常大导致RMSE的值很大，也就是可能再5%的时间区间内有了非常严重的**离群点**，这里解决则是可以用到平均绝对百分比误差MAPE。

![image](https://user-images.githubusercontent.com/88269254/169730633-262fd118-c098-476c-81e1-074e06ddf427.png)

总结三个实例来看，选择合适的评估指标很重要。每个评估指标都有其价值，但如果只从单一的评估指标出发去评估模型，往往会得出片面甚至错误的结论；只有通过一组互补的指标去评估模型，才能更好地发现并解决模型存在的问题，从而更好地解决实际业务场景中遇到的问题。

#### ROC曲线
AUC的计算和ROC曲线的绘制在上面已经提过，这里主要展示一下ROC曲线与P-R曲线相比有什么特点？
![image](https://user-images.githubusercontent.com/88269254/169734308-967e4df3-ebea-4fe2-9221-9c71ca82f468.png)

#### 余弦距离
余弦距离与欧氏距离有什么不同？余弦距离是否是一个严格定义的距离？

总体来说，欧氏距离体现数值上的**绝对差异**，而余弦距离体现方向上的**相对差异**。例如，统计两部剧的用户观看行为，用户A的观看向量为(0,1)，用户B为(1,0)；此时二者的余弦距离很大，而欧氏距离很小；我们分析两个用户对于不同视频的偏好，更关注相对差异，显然应当使用余弦距离。而当我们分析用户活跃度，以登陆次数(单位：次)和平均观看时长(单位：分钟)作为特征时，余弦距离会认为(1,10)、(10,100)两个用户距离很近；但显然这两个用户活跃度是有着极大差异的，此时我们更关注数值绝对差异，应当使用欧氏距离。

距离的定义：在一个集合中，如果每一对元素均可唯一确定一个实数，使得三条距离公理（**正定性**，**对称性**，**三角不等式**）成立，则该实数可称为这对元素之间的距离。余弦距离满足正定性和对称性，但是不满足三角不等式，因此它并**不是**严格定义的距离。证明如下：

首先是正定性，根据余弦距离定义可得以下公式，其中分子大于等于0，所以dist(A,B)≥0恒成立，A=B时取相等，因此满足正定性：

![image](https://user-images.githubusercontent.com/88269254/169735526-46bd27b4-b97e-4ab9-9494-7702851725e8.png)

其次是对称性，这里看上述公式，AB交换，结果不变，所以，dist(A,B)=dist(B,A)。

最后是三角不等式性质，这里给出简单的反例证明，更加明显的证明可以思考单位圆上余弦距离和欧式距离的关系。

![image](https://user-images.githubusercontent.com/88269254/169736626-2eee1553-8d6c-4a64-8041-ea631a33b0dd.png)

在机器学习领域，被俗称为距离，却不满足三条距离公理的不仅仅有余弦距离，还有KL距离（Kullback-Leibler Divergence），也叫作相对熵，它常用于计算两个分布之间的差异，但不满足对称性和三角不等式。

#### A/B测试
在对模型进行过充分的离线评估之后，为什么还要进行在线A/B测试？

1. 离线评估无法完全消除模型过拟合的影响，因此，得出的离线评估结果无法完全替代线上评估结果。
2. 离线评估无法完全还原线上的工程环境。一般来讲，离线评估往往不会考虑线上环境的延迟、数据丢失、标签数据缺失等情况。因此，离线评估的结果是理想工程环境下的结果。
3. 线上系统的某些商业指标在离线评估中无法计算。离线评估一般是针对模型本身进行评估，而与模型相关的其他指标，特别是商业指标，往往无法直接获得。比如，上线了新的推荐算法，离线评估往往关注的是ROC曲线、P-R曲线等的改进，而线上评估可以全面了解该推荐算法带来的用户点击率、留存时长、PV访问量等的变化。这些都要由A/B测试来进行全面的评估。

进行A/B测试的主要手段是进行**用户分桶**，即将用户分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型。在分桶的过程中，要注意样本的独立性和采样方式的无偏性，确保同一个用户每次只能分到同一个桶中，在分桶过程中所选取的user_id需要是一个随机数，这样才能保证桶中的样本是无偏的。

#### 超参数调优
模型评估方法和过拟合、欠拟合问题前面已经提过，这里说几种超参数调优的方法。

- **网格搜索**

  网格搜索可能是最简单、应用最广泛的超参数搜索算法，它通过查找搜索范围内的**所有的点**来确定最优值。如果采用较大的搜索范围以及较小的步长，网格搜索有很大概率找到全局最优值。然而，这种搜索方案十分消耗计算资源和时间，特别是需要调优的超参数比较多的时候。因此，在实际应用中，网格搜索法一般会先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；然后会逐渐缩小搜索范围和步长，来寻找更精确的最优值。这种操作方案可以降低所需的时间和计算量，但由于目标函数一般是非凸的，所以很可能会错过全局最优值。

- **随机搜索**

  随机搜索的思想与网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中**随机选取样本点**。它的理论依据是，如果样本点集足够大，那么通过随机采样也能大概率地找到全局最优值，或其近似值。随机搜索一般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果也是没法保证的。
  
- **贝叶斯优化算法**

  贝叶斯优化算法在寻找最优最值参数时，采用了与网格搜索、随机搜索完全不同的方法。网格搜索和随机搜索在测试一个新点时，会忽略前一个点的信息；而贝叶斯优化算法则充分利用了之前的信息。贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它学习目标函数形状的方法是，首先根据先验分布，假设一个搜集函数；然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。对于贝叶斯优化算法，有一个需要注意的地方，一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值。为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，“探索”就是在还未取样的区域获取采样点；而“利用”则是根据后验分布在最可能出现全局最值的区域进行采样。
